# Solution & Theory of Change

## The Causality Chain Methodology

Kyanos doesn't just report problems. We trace them to root causes and provide fixes campaigns can actually implement.

### The Four Steps

1. **Observe:** What does the AI surface say?
2. **Trace:** Where did it get that information?
3. **Diagnose:** What's the root cause of the error?
4. **Prescribe:** Specific fix for the source, not the symptom

**Only recommend actions the campaign can take. No "shoulda/woulda."**

<div class="callout-info">
<div class="callout-title">Why Causality Matters</div>
<p>Traditional SEO tools highlight problems. We diagnose root causes and deliver fixes.</p>
<p>If ChatGPT says a candidate supports a policy they oppose, we trace the error to its source: maybe a Wikipedia entry, a misquoted news article, or a missing issues page on the campaign website.</p>
<p>Then we tell the campaign <strong>exactly what needs to happen</strong>, whether that's writing new content, updating existing pages, or making technical fixes to the website's structured data. We package these recommendations so they can easily hand them off to the people who need to execute: the comms director gets the messaging guidance, the web developer gets the technical specs.</p>
<p>And we don't just hand over a report and walk away. <strong>We monitor execution and act as a coach</strong>, tracking whether fixes get implemented, confirming when AI systems update their responses, and keeping the pressure on until the job is done.</p>
</div>

*For a technical overview of how AI chatbots retrieve and process web content, see [Appendix 4: The Journey of a Prompt](ky-appendix-e-prompt-journey.html).*

## Panopticon: The Core Product

Panopticon is our flagship product. It works in three phases: **Monitor → Prioritize → Act**

Every customer gets all three phases. This is not a tiered feature set. It's a complete methodology.

### Phase 1: Monitor

**Purpose:** Automated monitoring of AI platforms and search engines

**How It Works:**

- Queries AI surfaces using our Bentham extraction infrastructure
- Core surfaces: Google AI Overviews, ChatGPT, Meta AI
- Optional: Perplexity, Copilot, Gemini, Claude, Grok, and others
- Tests questions voters actually ask about the candidate
- Shows exactly what voters see when they enter a prompt about the candidate
- WatchTower detects geographic variation (Statewide/National tiers)

**Monitoring Frequency:**

- Monthly (standard)
- Weekly (premium)
- Daily (premium)

**Deliverable:** Dashboard showing exactly what voters see across platforms, with sample AI and search responses

### Phase 2: Prioritize

**Purpose:** Trace errors to root causes and rank by impact

**How It Works:**

- Analyzes Monitor findings to identify problems
- **Traces causality:** Where does the information come from? Wikipedia? Ballotpedia? News articles? Campaign site?
- Identifies the fixable root cause of each error
- Ranks issues by: **(Voter Reach × Error Severity × Fixability)**
- Focuses only on things the campaign can actually change

**Deliverable:** Ranked priority list showing what to fix first and why

### Phase 3: Act

**Purpose:** Specific, actionable remediation instructions

**How It Works:**

- Provides step-by-step instructions for each issue
- **Knows the tech stack:** Instructions tailored to the campaign's CMS (WordPress, Squarespace, NationBuilder, etc.)
- **Targeted delivery:**
    - Approver gets the recommendation (what and why)
    - Implementer gets exact instructions for their system
- Includes templates, URLs, and code snippets ready to use

**Deliverable:** Action cards with numbered steps that campaign teams can execute immediately

## Theory of Change

### Immediate Impact (Campaign Level)

1. Campaign monitors its AI representation
2. Identifies inaccuracies and their root causes
3. Implements specific fixes (schema markup, content updates, source corrections)
4. AI systems update their responses over time
5. Voters receive accurate information about the candidate

### Systemic Impact (Movement Level)

1. Progressive campaigns collectively improve their AI visibility
2. AI systems receive better training signals from progressive sources
3. Platform accountability becomes possible through documented evidence
4. Progressives gain an advantage in the AI information environment

### Watchdog Impact (Democracy Level)

1. WatchTower detects geographic manipulation
2. Research Institute documents evidence of platform bias
3. Findings inform policy advocacy and public awareness
4. AI platforms face accountability pressure

## What Makes This Different

### Compared to Generic SEO

- **Political context:** We understand campaigns, not just keywords
- **AI-specific:** Optimized for AI answer generation, not just search ranking
- **Causality focus:** We trace problems to root causes
- **Actionable fixes:** We deliver solutions, not just problem reports
- **CMS-aware:** Instructions match the campaign's actual tech stack

### Compared to General AI Monitoring

- **Campaign-specific prompts:** Questions voters actually ask
- **Progressive alignment:** Built for Democratic campaigns and organizations
- **Actionable output:** Not just reports, but fixes
- **Regional detection:** Geographic variation analysis

### Compared to DIY Approaches

- **Systematic methodology:** Not ad hoc checks
- **Scale:** Monitoring across multiple surfaces simultaneously
- **Expertise:** Deep understanding of how AI systems source information
- **Continuous:** Regular monitoring, not one-time audits

---

<div class="callout-bottomline">
<p><strong>We don't just tell you what's wrong. We do what SEO does that matters—and a whole lot more. We tell you exactly how to fix it.</strong></p>
</div>
